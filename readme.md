# ğŸ§  Neuradynamics (Pragya) Policy RAG Agent

> **AI Engineering Intern Assignment Submission**  
> **Author:** Nikhil Kumar Vidyarthi  
> **Date:** February 2026  

---

## ğŸ“– Project Overview

This project implements a **Retrieval-Augmented Generation (RAG)** system designed to serve as an intelligent FAQ assistant for **Pragya (Neuradynamics)**. The system enables users to ask questions related to the company's **Terms of Service** and **Privacy Policy**, returning accurate, grounded, and context-supported answers.

Unlike traditional chatbots, this agent is designed to be **conservative, factual, and safe**. It strictly refuses to answer questions outside its knowledge base, preventing hallucinations and ensuring reliability.

### ğŸ¯ Problem Statement
Customers and internal support teams often need to manually search policy documents to find relevant clauses. This process is time-consuming and inefficient. This RAG system automates policy retrieval and explanation, improving accessibility and response accuracy.

---

## ğŸš€ Key Features

### ğŸ” Semantic Search
Uses **ChromaDB** combined with **Google Gemini Embeddings** to retrieve the most relevant policy sections based on user queries.

### âš¡ Gemini 1.5 Flash Powered Reasoning
Leverages Google's **Gemini 1.5 Flash** model to generate fast, cost-efficient, and high-quality responses grounded in retrieved content.

### ğŸ§ª Automated Evaluation Framework
Includes a testing suite (`evaluate.py`) that benchmarks system performance across:

- Answerable Queries
- Ambiguous Queries
- Unanswerable Queries

### ğŸ›¡ï¸ Hallucination Prevention
The agent strictly follows prompt guardrails and refuses to fabricate answers when required information is unavailable.

---

## ğŸ—ï¸ System Architecture

```
User Query
    â†“
Query Embedding (Gemini Embeddings)
    â†“
Vector Search (ChromaDB)
    â†“
Retrieve Relevant Policy Chunks
    â†“
Gemini 1.5 Flash LLM
    â†“
Grounded Answer + Source Context
```

---

## ğŸ“‚ Project Structure

```
neuradynamics-rag/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ policy.txt            # Source document (Terms & Privacy Policy)
â”œâ”€â”€ chroma_db/                # Local vector database (generated after ingestion)
â”œâ”€â”€ ingest.py                 # Script for data loading, chunking, and indexing
â”œâ”€â”€ rag_agent.py              # Chat interface and inference pipeline
â”œâ”€â”€ evaluate.py               # Automated testing and evaluation framework
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ .env                      # API key configuration (excluded from version control)
â””â”€â”€ README.md                 # Project documentation
```

---

## ğŸ› ï¸ Installation & Setup

### âœ… Prerequisites

- Python **3.10 or higher**
- Google Cloud API Key (Gemini access)

---

### ğŸ“¥ Clone Repository

```bash
git clone https://github.com/vidyarthinikhil09/neuradynamics-rag-assignment.git
cd neuradynamics-rag-assignment
```

---

### ğŸ§ª Create Virtual Environment

```bash
python -m venv venv
```

#### Activate Environment

**Windows**
```bash
venv\Scripts\activate
```

**Mac/Linux**
```bash
source venv/bin/activate
```

---

### ğŸ“¦ Install Dependencies

```bash
pip install -r requirements.txt
```

If `requirements.txt` is missing:

```bash
pip install langchain-google-genai langchain-chroma langchain-community python-dotenv pandas tabulate
```

---

### ğŸ”‘ Configure API Key

Create a `.env` file in the root directory:

```
GOOGLE_API_KEY=your_actual_api_key_here
```

---

## ğŸƒ Usage Guide

The system operates in two main stages:

---

### ğŸ§  Step 1: Data Ingestion (Build Knowledge Base)

```bash
python ingest.py
```

âœ” Loads policy document  
âœ” Splits into semantic chunks  
âœ” Generates embeddings  
âœ” Stores vectors in ChromaDB  

Expected Output:

```
Ingestion complete! Database rebuilt with Gemini embeddings.
```

---

### ğŸ’¬ Step 2: Run RAG Agent

```bash
python rag_agent.py
```

Users can type policy-related questions interactively.

To exit:
```
exit
```
or
```
quit
```

---

### ğŸ“Š Step 3: Run Automated Evaluation

```bash
python evaluate.py
```

Results are generated in:

```
evaluation_report.md
```

---

## ğŸ§  Architecture & Design Decisions

---

### ğŸ“‘ Chunking Strategy

- **Chunk Size:** 1000 characters  
- **Overlap:** 200 characters  

#### Reasoning
Legal documents contain dense contextual information. Overlapping chunks preserve continuity and improve retrieval accuracy.

---

### âœï¸ Prompt Engineering Evolution

#### Iteration 1 (Initial Prompt)
```
You are a helpful assistant. Answer the user question based on the context.
```

âŒ Result: Occasional hallucinations and speculative answers.

---

#### Iteration 2 (Final Prompt)
```
You are an intelligent assistant for Pragya. Answer strictly using provided context.

RULES:
1. Use ONLY the provided context.
2. If answer is missing, respond:
"I cannot answer this question using the provided policy documents."
```

âœ… Result: Reliable grounded responses and safe refusal handling.

---

### âš™ï¸ Tech Stack Justification

| Technology | Purpose | Reason for Selection |
|------------|------------|----------------------|
| LangChain | RAG orchestration | Simplifies pipeline integration |
| ChromaDB | Vector storage | Lightweight and open-source |
| Gemini Embeddings | Semantic understanding | High-quality contextual vectorization |
| Gemini 1.5 Flash | LLM reasoning | Fast inference and large context window |

---

## ğŸ“Š Evaluation Results

| Category | Description | Performance |
|------------|----------------|----------------|
| Answerable | Clearly present in document | âœ… 100% Retrieval Accuracy |
| Edge Cases | Requires combining multiple clauses | âœ… Consistent Logical Responses |
| Unanswerable | Information not present in policy | âœ… Correct Refusal Behaviour |

---

### ğŸ§ª Evaluation Methodology

- Structured query test dataset
- Manual ground truth comparison
- Behavioral validation for refusal scenarios

---

## âš¡ Performance Observations

- Fast query latency due to Gemini Flash model
- Efficient local vector retrieval using ChromaDB
- Stable performance across multi-clause queries

---

## ğŸ›¡ï¸ Safety & Error Handling

- Explicit hallucination prevention via prompt constraints
- Graceful handling of missing context
- Secure API key storage using `.env`

---

## ğŸ”® Future Improvements

### ğŸ” Hybrid Search
Combine semantic search with BM25 keyword search for improved retrieval recall.

### ğŸ¯ Reranking Layer
Introduce cross-encoder or LLM reranking to improve precision.

### ğŸ“Œ Source Highlighting
Return exact clause or line references.

### ğŸ§  Query Rewriting
Improve ambiguous query interpretation.

### ğŸ“Š Monitoring & Logging
Track query accuracy and model performance.

### ğŸ–¥ï¸ UI Integration
Develop Streamlit or web interface for improved user experience.

---

## ğŸ’» Tested Environment

- Python 3.10+
- Windows 11

---

## ğŸ“¬ Contact

**Developed By:** Nikhil Kumar Vidyarthi  
**Email:** vidyarthinikhil5@gmail.com   
**GitHub:** [\[Your GitHub Profile\]](https://github.com/vidyarthinikhil09)

---

## â­ Acknowledgements

- LangChain Framework
- Google Gemini API
- ChromaDB Vector Store

---

## ğŸ“„ License

This project is developed for educational and evaluation purposes.
